import os
import pandas as pd
import numpy as np
import re

# Define the path to your spam and ham folders for train and dev sets
train_spam_folder = '/Users/baljinnyam/Downloads/spam_data/train/spam'
train_ham_folder = '/Users/baljinnyam/Downloads/spam_data/train/ham'
dev_spam_folder = '/Users/baljinnyam/Downloads/spam_data/dev/spam'
dev_ham_folder = '/Users/baljinnyam/Downloads/spam_data/dev/ham'

# Define a function to read in the email text from a folder and return a dataframe of word counts
def create_word_counts_dataframe(folder_path):
    # Initialize an empty list to store the email text
    email_text = []

    # Loop through each file in the folder and append the contents to the email_text list
    for filename in os.listdir(folder_path):
        try:
            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as f:
                email_text.append(f.read())
        except UnicodeDecodeError:
            print(f"Error: could not read file {filename} due to encoding issue")

    # Use the CountVectorizer from scikit-learn to transform the email text into a sparse matrix of word counts
    from sklearn.feature_extraction.text import CountVectorizer

    vectorizer = CountVectorizer()
    X = vectorizer.fit_transform(email_text)

    # Create a pandas dataframe from the sparse matrix
    df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())

    return df

# Define a function to calculate the probability of each word appearing in a spam or non-spam email
def calculate_word_probabilities(spam_df, ham_df, a=1):
    # Calculate the total number of words in the spam and non-spam emails
    total_spam_words = spam_df.sum().sum()
    total_ham_words = ham_df.sum().sum()

    # Calculate the total number of emails in the spam and non-spam datasets
    num_spam_emails = spam_df.shape[0]
    num_ham_emails = ham_df.shape[0]

    # Calculate the probability of a spam email and a non-spam email
    p_spam = num_spam_emails / (num_spam_emails + num_ham_emails)
    p_ham = num_ham_emails / (num_spam_emails + num_ham_emails)

    # Calculate the probability of each word appearing in a spam email
    spam_word_probs = {}
    for word in spam_df.columns:
        count = spam_df[word].sum()
        prob = (count + a) / (total_spam_words + a * len(spam_df.columns))
        spam_word_probs[word] = prob

    # Calculate the probability of each word appearing in a non-spam email
    ham_word_probs = {}
    for word in ham_df.columns:
        count = ham_df[word].sum()
        prob = (count + a) / (total_ham_words + a * len(ham_df.columns))
        ham_word_probs[word] = prob

    return p_spam, p_ham, spam_word_probs, ham_word_probs

# Create dataframes for the train_spam and train_ham folders
train_spam_df = create_word_counts_dataframe(train_spam_folder)
train_ham_df = create_word_counts_dataframe(train_ham_folder)

# Create dataframes for the dev_spam and dev_ham folders
dev_spam_df = create_word_counts_dataframe(dev_spam_folder)
dev_ham_df = create_word_counts_dataframe(dev_ham_folder)

# Calculate the probability
p_spam, p_ham, spam_word_probs, ham_word_probs = calculate_word_probabilities(train_spam_df, train_ham_df)



